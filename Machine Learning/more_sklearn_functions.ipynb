{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cba066dd",
   "metadata": {},
   "source": [
    "# More Commonly Used Functions in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe5253",
   "metadata": {},
   "source": [
    "In this notebook, we will cover even more commonly used functions in the scikit-learn library, excluding those already covered in the previous notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23afa82f",
   "metadata": {},
   "source": [
    "## 1. RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6a756",
   "metadata": {},
   "source": [
    "The `RobustScaler` function is used to scale features using statistics that are robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: RobustScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 100],\n",
    "    'feature2': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Scale features\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "print(f'Scaled data: {scaled_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95c75e",
   "metadata": {},
   "source": [
    "## 2. PowerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07523c",
   "metadata": {},
   "source": [
    "The `PowerTransformer` function is used to apply a power transform to make data more Gaussian-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: PowerTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply power transform\n",
    "transformer = PowerTransformer()\n",
    "transformed_data = transformer.fit_transform(df)\n",
    "\n",
    "print(f'Transformed data: {transformed_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278191eb",
   "metadata": {},
   "source": [
    "## 3. QuantileTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d879a1b",
   "metadata": {},
   "source": [
    "The `QuantileTransformer` function is used to transform features to follow a uniform or normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a621eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: QuantileTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply quantile transform\n",
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "transformed_data = transformer.fit_transform(df)\n",
    "\n",
    "print(f'Transformed data: {transformed_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15798b7a",
   "metadata": {},
   "source": [
    "## 4. Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c3248",
   "metadata": {},
   "source": [
    "The `Binarizer` function is used to binarize data (set feature values to 0 or 1) based on a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Binarizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Binarize features\n",
    "binarizer = Binarizer(threshold=25)\n",
    "binarized_data = binarizer.fit_transform(df)\n",
    "\n",
    "print(f'Binarized data: {binarized_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f1289",
   "metadata": {},
   "source": [
    "## 5. FeatureHasher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d6946",
   "metadata": {},
   "source": [
    "The `FeatureHasher` function is used to transform categorical features into a sparse matrix of occurrence counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: FeatureHasher\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "# Sample data\n",
    "data = [{'dog': 1, 'cat': 2}, {'dog': 2, 'run': 5}]\n",
    "\n",
    "# Apply feature hashing\n",
    "hasher = FeatureHasher(n_features=10, input_type='dict')\n",
    "hashed_features = hasher.fit_transform(data)\n",
    "\n",
    "print(f'Hashed features: {hashed_features.toarray()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e304d5d",
   "metadata": {},
   "source": [
    "## 6. Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d657c94",
   "metadata": {},
   "source": [
    "The `Normalizer` function is used to normalize samples individually to unit norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352754c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Normalizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Normalize features\n",
    "normalizer = Normalizer()\n",
    "normalized_data = normalizer.fit_transform(df)\n",
    "\n",
    "print(f'Normalized data: {normalized_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e9a1b",
   "metadata": {},
   "source": [
    "## 7. KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9694c921",
   "metadata": {},
   "source": [
    "The `KMeans` function is used for clustering data into K distinct clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c9623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(df)\n",
    "\n",
    "print(f'Cluster centers: {kmeans.cluster_centers_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798c597",
   "metadata": {},
   "source": [
    "## 8. DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88667702",
   "metadata": {},
   "source": [
    "The `DBSCAN` function is used for clustering data based on density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd511fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5, 8, 8, 25],\n",
    "    'feature2': [10, 20, 30, 40, 50, 80, 85, 25]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=10, min_samples=2)\n",
    "clusters = dbscan.fit_predict(df)\n",
    "\n",
    "print(f'Clusters: {clusters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0b6c3",
   "metadata": {},
   "source": [
    "## 9. Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b85a7",
   "metadata": {},
   "source": [
    "The `mean_squared_error` function is used to evaluate the accuracy of a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6347e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Sample data\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "\n",
    "# Compute MSE\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac77ae",
   "metadata": {},
   "source": [
    "## 10. Silhouette Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0be15",
   "metadata": {},
   "source": [
    "The `silhouette_score` function is used to evaluate the quality of clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Silhouette Score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "labels = kmeans.fit_predict(df)\n",
    "\n",
    "# Compute Silhouette Score\n",
    "score = silhouette_score(df, labels)\n",
    "print(f'Silhouette Score: {score}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
