{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da3419c9",
      "metadata": {
        "id": "da3419c9"
      },
      "source": [
        "# Most Used Functions in Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e37df443",
      "metadata": {
        "id": "e37df443"
      },
      "source": [
        "Dimensionality reduction techniques are used to reduce the number of features in a dataset while retaining as much information as possible. This notebook covers some of the most commonly used functions for dimensionality reduction using popular Python libraries such as scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebe62dd4",
      "metadata": {
        "id": "ebe62dd4"
      },
      "source": [
        "## 1. Principal Component Analysis (PCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec775d42",
      "metadata": {
        "id": "ec775d42"
      },
      "source": [
        "PCA is a widely used technique for dimensionality reduction that transforms the data to a new coordinate system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "076f3e36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "076f3e36",
        "outputId": "e0b0a3b1-4a37-4839-dd29-6d015c0a8ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced data:\n",
            "[[ 4.89897949e+00  3.84592537e-16]\n",
            " [ 2.44948974e+00 -1.28197512e-16]\n",
            " [-0.00000000e+00 -0.00000000e+00]\n",
            " [-2.44948974e+00  1.28197512e-16]\n",
            " [-4.89897949e+00  2.56395025e-16]]\n"
          ]
        }
      ],
      "source": [
        "# Example: Principal Component Analysis using scikit-learn\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'feature1': [1, 2, 3, 4, 5],\n",
        "    'feature2': [2, 4, 6, 8, 10],\n",
        "    'feature3': [5, 4, 3, 2, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)\n",
        "reduced_data = pca.fit_transform(df)\n",
        "\n",
        "print(f'Reduced data:\\n{reduced_data}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6f44353",
      "metadata": {
        "id": "c6f44353"
      },
      "source": [
        "## 2. Linear Discriminant Analysis (LDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca003ff4",
      "metadata": {
        "id": "ca003ff4"
      },
      "source": [
        "LDA is a supervised dimensionality reduction technique that maximizes class separability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fc398fa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc398fa5",
        "outputId": "65419ab2-0823-43ff-98a4-03582c23f5d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced data:\n",
            "[[-1.25]\n",
            " [-0.75]\n",
            " [-0.25]\n",
            " [ 0.25]\n",
            " [ 0.75]\n",
            " [ 1.25]]\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Discriminant Analysis using scikit-learn\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'feature1': [1, 2, 3, 4, 5, 6],\n",
        "    'feature2': [2, 4, 6, 8, 10, 12],\n",
        "    'target': [0, 1, 0, 1, 0, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Apply LDA\n",
        "lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "X = df[['feature1', 'feature2']]\n",
        "y = df['target']\n",
        "reduced_data = lda.fit_transform(X, y)\n",
        "\n",
        "print(f'Reduced data:\\n{reduced_data}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fb127a6",
      "metadata": {
        "id": "5fb127a6"
      },
      "source": [
        "## 3. t-SNE (t-Distributed Stochastic Neighbor Embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "654e07c6",
      "metadata": {
        "id": "654e07c6"
      },
      "source": [
        "t-SNE is a technique for visualizing high-dimensional data by reducing it to two or three dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "61c0af4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61c0af4e",
        "outputId": "4055e998-ffc0-439c-9cff-64ac6e67f5fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced data:\n",
            "[[-165.49147    39.94785 ]\n",
            " [-121.394966   39.8173  ]\n",
            " [ -68.188255   39.659157]\n",
            " [ -11.135759   39.489376]\n",
            " [  42.070732   39.330883]\n",
            " [  86.16744    39.199203]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'feature1': [1, 2, 3, 4, 5, 6],\n",
        "    'feature2': [2, 4, 6, 8, 10, 12],\n",
        "    'feature3': [5, 4, 3, 2, 1, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Apply t-SNE with adjusted perplexity\n",
        "tsne = TSNE(n_components=2, perplexity=2, random_state=42)\n",
        "reduced_data = tsne.fit_transform(df)\n",
        "\n",
        "print(f'Reduced data:\\n{reduced_data}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "509f2d32",
      "metadata": {
        "id": "509f2d32"
      },
      "source": [
        "## 4. Non-Negative Matrix Factorization (NMF)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c623c612",
      "metadata": {
        "id": "c623c612"
      },
      "source": [
        "NMF is a technique for factorizing non-negative data into non-negative components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83f13ea3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83f13ea3",
        "outputId": "50866ea1-f0d8-4336-8015-7a0e7845e6c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced data:\n",
            "[[0.58426299 0.        ]\n",
            " [1.28487377 0.01107156]\n",
            " [1.21225685 0.51167486]\n",
            " [0.26198713 1.56145624]\n",
            " [0.         2.18055511]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_nmf.py:1710: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Example: Non-Negative Matrix Factorization using scikit-learn\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'feature1': [1, 2, 3, 4, 5],\n",
        "    'feature2': [2, 4, 6, 8, 10],\n",
        "    'feature3': [1, 3, 5, 7, 9]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Apply NMF\n",
        "nmf = NMF(n_components=2, random_state=42)\n",
        "reduced_data = nmf.fit_transform(df)\n",
        "\n",
        "print(f'Reduced data:\\n{reduced_data}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c93d25c",
      "metadata": {
        "id": "0c93d25c"
      },
      "source": [
        "## 5. Independent Component Analysis (ICA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "303aa524",
      "metadata": {
        "id": "303aa524"
      },
      "source": [
        "ICA is a technique for separating a multivariate signal into additive, independent components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e7738412",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7738412",
        "outputId": "32a1dea8-e9b3-473a-955b-ef5e7e25cd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced data:\n",
            "[[-1.41421356  1.41421356]\n",
            " [-0.70710678  0.70710678]\n",
            " [ 0.          0.        ]\n",
            " [ 0.70710678 -0.70710678]\n",
            " [ 1.41421356 -1.41421356]]\n"
          ]
        }
      ],
      "source": [
        "# Example: Independent Component Analysis using scikit-learn\n",
        "from sklearn.decomposition import FastICA\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'feature1': [1, 2, 3, 4, 5],\n",
        "    'feature2': [2, 4, 6, 8, 10],\n",
        "    'feature3': [1, 3, 5, 7, 9]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Apply ICA\n",
        "ica = FastICA(n_components=2, random_state=42)\n",
        "reduced_data = ica.fit_transform(df)\n",
        "\n",
        "print(f'Reduced data:\\n{reduced_data}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f2d6be9",
      "metadata": {
        "id": "6f2d6be9"
      },
      "source": [
        "## 6. Truncated SVD (Singular Value Decomposition)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11e8dc7f",
      "metadata": {
        "id": "11e8dc7f"
      },
      "source": [
        "Truncated SVD is a technique for dimensionality reduction that is particularly useful for sparse data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ad1d0269",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad1d0269",
        "outputId": "503f18d9-398d-45ee-ee0d-2e251cf088c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced data:\n",
            "[[ 3.58705934  1.06442721]\n",
            " [ 8.75770068  0.55016253]\n",
            " [13.92834202  0.03589786]\n",
            " [19.09898335 -0.47836682]]\n"
          ]
        }
      ],
      "source": [
        "# Example: Truncated SVD using scikit-learn\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
        "\n",
        "# Apply Truncated SVD\n",
        "svd = TruncatedSVD(n_components=2)\n",
        "reduced_data = svd.fit_transform(data)\n",
        "\n",
        "print(f'Reduced data:\\n{reduced_data}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EFpqf9TQRwa3"
      },
      "id": "EFpqf9TQRwa3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}