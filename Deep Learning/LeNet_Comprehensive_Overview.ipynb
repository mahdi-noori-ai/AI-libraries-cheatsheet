{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e672704c",
   "metadata": {},
   "source": [
    "\n",
    "# LeNet: A Comprehensive Overview\n",
    "\n",
    "This notebook provides an in-depth overview of the LeNet architecture, including its history, mathematical foundation, implementation, usage, advantages and disadvantages, and more. We'll also include visualizations and a discussion of the model's impact and applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07837417",
   "metadata": {},
   "source": [
    "\n",
    "## History of LeNet\n",
    "\n",
    "LeNet was developed by Yann LeCun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner in 1998, and is one of the earliest convolutional neural networks (CNNs). It was designed to recognize handwritten digits in the MNIST dataset, which was a challenging problem at the time.\n",
    "\n",
    "LeNet-5, the most well-known variant of the architecture, was revolutionary for its ability to automatically learn features from images, a significant departure from traditional hand-engineered features used in earlier machine learning models. This architecture laid the groundwork for modern deep learning models, which are now pervasive in computer vision applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b699a7",
   "metadata": {},
   "source": [
    "\n",
    "## Mathematical Foundation of LeNet\n",
    "\n",
    "### Architecture\n",
    "\n",
    "LeNet-5 consists of the following layers:\n",
    "\n",
    "1. **Input Layer**: The input to LeNet-5 is a 32x32 pixel grayscale image.\n",
    "2. **C1 - Convolutional Layer**: Applies 6 convolutional filters of size 5x5, resulting in a 28x28 feature map. The equation for a single feature map can be expressed as:\n",
    "\n",
    "\\[\n",
    "C1_i = \\text{ReLU}(X \\ast W_i + b_i)\n",
    "\\]\n",
    "\n",
    "Where \\( X \\) is the input image, \\( W_i \\) is the filter, and \\( b_i \\) is the bias.\n",
    "\n",
    "3. **S2 - Subsampling Layer (Pooling)**: Applies average pooling with a 2x2 window and a stride of 2, reducing the feature map size to 14x14.\n",
    "\n",
    "\\[\n",
    "S2_i = \\frac{1}{4} \\sum_{m,n} C1_{i, m+n}\n",
    "\\]\n",
    "\n",
    "4. **C3 - Convolutional Layer**: Applies 16 convolutional filters, resulting in a 10x10 feature map.\n",
    "5. **S4 - Subsampling Layer (Pooling)**: Similar to S2, reduces the feature map size to 5x5.\n",
    "6. **C5 - Fully Connected Convolutional Layer**: Flattens the feature maps and connects them to 120 neurons.\n",
    "7. **F6 - Fully Connected Layer**: Connects C5 to 84 neurons.\n",
    "8. **Output Layer**: Connects F6 to 10 output neurons, one for each digit class.\n",
    "\n",
    "### Activation Function\n",
    "\n",
    "LeNet-5 uses the ReLU activation function:\n",
    "\n",
    "\\[\n",
    "\\text{ReLU}(x) = \\max(0, x)\n",
    "\\]\n",
    "\n",
    "ReLU introduces non-linearity into the model, allowing it to learn complex patterns.\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "LeNet-5 typically uses the cross-entropy loss for classification tasks:\n",
    "\n",
    "\\[\n",
    "\\text{Loss} = -\\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)\n",
    "\\]\n",
    "\n",
    "Where \\( y_i \\) is the true label and \\( \\hat{y}_i \\) is the predicted probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c70eb2",
   "metadata": {},
   "source": [
    "\n",
    "## Implementation in Python\n",
    "\n",
    "We'll implement the LeNet architecture using TensorFlow and Keras on the MNIST dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc8fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Build the AlexNet model adapted for CIFAR-10\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(96, (3, 3), strides=1, activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "    layers.Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# Plot the training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Plot sample predictions\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "predictions = model.predict(x_test[:10])\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.xlabel(f\"Pred: {class_names[predictions[i].argmax()]}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb808a0",
   "metadata": {},
   "source": [
    "\n",
    "## Pros and Cons of LeNet\n",
    "\n",
    "### Advantages\n",
    "- **Simplicity**: LeNet has a straightforward architecture, making it easy to implement and understand.\n",
    "- **Efficiency**: The model is lightweight and requires fewer computational resources compared to more complex architectures.\n",
    "- **Foundational Model**: LeNet serves as a foundation for understanding more complex CNN architectures.\n",
    "\n",
    "### Disadvantages\n",
    "- **Limited Capacity**: LeNet's simplicity limits its ability to handle more complex and larger datasets.\n",
    "- **Outdated**: While revolutionary at its time, LeNet is outperformed by modern CNN architectures in many tasks.\n",
    "- **Low Flexibility**: The fixed architecture makes it less adaptable to different types of data or tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b290d",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "LeNet was a groundbreaking architecture that introduced the concept of convolutional neural networks to the world. While its simplicity and efficiency made it a perfect model for early image recognition tasks like digit classification, its limitations are apparent in today's deep learning landscape. However, understanding LeNet is crucial for anyone interested in the history and development of CNNs, as it laid the groundwork for more advanced models that are widely used today.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
