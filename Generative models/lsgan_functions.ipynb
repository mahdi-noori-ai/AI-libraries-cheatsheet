{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5891caac",
   "metadata": {},
   "source": [
    "# Most Used Functions in LSGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a396d",
   "metadata": {},
   "source": [
    "Least Squares GAN (LSGAN) is a type of Generative Adversarial Network (GAN) that uses least squares loss for the discriminator. This helps to address issues with the original GAN formulation, such as vanishing gradients and instability during training. In this notebook, we will cover some of the most commonly used functions and techniques for implementing a simplified version of LSGAN using TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa7f42",
   "metadata": {},
   "source": [
    "## 1. Building the Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b38bc1",
   "metadata": {},
   "source": [
    "The generator in LSGAN generates images from random noise. It uses a series of transposed convolutional layers to upsample the input noise vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Function to build the generator\n",
    "def build_generator():\n",
    "    inputs = Input(shape=(100,))\n",
    "    x = Dense(256 * 7 * 7, activation='relu')(inputs)\n",
    "    x = Reshape((7, 7, 256))(x)\n",
    "    x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(1, (5, 5), strides=(1, 1), padding='same')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "# Instantiate and summarize the generator\n",
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dd8713",
   "metadata": {},
   "source": [
    "## 2. Building the Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0c71a",
   "metadata": {},
   "source": [
    "The discriminator in LSGAN distinguishes between real and fake images. It uses a series of convolutional layers to downsample the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, LeakyReLU, Flatten\n",
    "\n",
    "# Function to build the discriminator\n",
    "def build_discriminator():\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "    x = Conv2D(64, (5, 5), strides=(2, 2), padding='same')(inputs)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)  # No activation for least squares loss\n",
    "    return Model(inputs, x)\n",
    "\n",
    "# Instantiate and summarize the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='mse', metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ccfaf",
   "metadata": {},
   "source": [
    "## 3. Building the LSGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b1037",
   "metadata": {},
   "source": [
    "The LSGAN combines the generator and discriminator. The generator tries to generate realistic images, while the discriminator distinguishes between real and fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function to build the LSGAN\n",
    "def build_lsgan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    inputs = Input(shape=(100,))\n",
    "    generated_image = generator(inputs)\n",
    "    validity = discriminator(generated_image)\n",
    "    model = Model(inputs, validity)\n",
    "    model.compile(optimizer=Adam(0.0002, 0.5), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the LSGAN\n",
    "lsgan = build_lsgan(generator, discriminator)\n",
    "lsgan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc390f",
   "metadata": {},
   "source": [
    "## 4. Training the LSGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41bf1c",
   "metadata": {},
   "source": [
    "Training the LSGAN involves alternating between training the discriminator and training the generator using least squares loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc732d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "(X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "\n",
    "# Training parameters\n",
    "epochs = 10000\n",
    "batch_size = 64\n",
    "half_batch = batch_size // 2\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Train discriminator with real samples\n",
    "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "    X_real, y_real = X_train[idx], np.ones((half_batch, 1))\n",
    "    d_loss_real = discriminator.train_on_batch(X_real, y_real)\n",
    "    \n",
    "    # Train discriminator with fake samples\n",
    "    noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "    X_fake = generator.predict(noise)\n",
    "    y_fake = np.zeros((half_batch, 1))\n",
    "    d_loss_fake = discriminator.train_on_batch(X_fake, y_fake)\n",
    "    \n",
    "    # Train generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    y_gan = np.ones((batch_size, 1))\n",
    "    g_loss = lsgan.train_on_batch(noise, y_gan)\n",
    "    \n",
    "    # Summarize the loss for this epoch\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f'{epoch+1}/{epochs} [D real: {d_loss_real:.3f}] [D fake: {d_loss_fake:.3f}] [G loss: {g_loss:.3f}]')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
