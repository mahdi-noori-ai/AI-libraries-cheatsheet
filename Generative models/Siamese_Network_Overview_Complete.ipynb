{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9b7b5d",
   "metadata": {},
   "source": [
    "\n",
    "# Siamese Networks: A Comprehensive Overview\n",
    "\n",
    "This notebook provides an in-depth overview of Siamese Networks, including their history, mathematical foundation, implementation, usage, advantages and disadvantages, and more. We'll also include visualizations and a discussion of the model's impact and applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf67eb",
   "metadata": {},
   "source": [
    "\n",
    "## History of Siamese Networks\n",
    "\n",
    "Siamese Networks were introduced by Bromley and LeCun in 1993 in the context of signature verification in the paper \"Signature Verification using a Siamese Time Delay Neural Network.\" The key idea behind Siamese Networks is to learn a similarity metric between pairs of inputs, which makes them particularly useful for tasks where the goal is to determine whether two inputs are similar or different, such as in face verification, signature verification, and one-shot learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd531ac7",
   "metadata": {},
   "source": [
    "\n",
    "## Mathematical Foundation of Siamese Networks\n",
    "\n",
    "### Siamese Network Architecture\n",
    "\n",
    "A Siamese Network consists of two identical sub-networks that share the same weights and are used to process two different inputs. The outputs of the two sub-networks are then compared using a distance metric, such as the Euclidean distance or cosine similarity.\n",
    "\n",
    "1. **Input Pairs**: The Siamese Network takes two inputs, \\( x_1 \\) and \\( x_2 \\), and passes them through the same network \\( f(\\cdot) \\).\n",
    "\n",
    "\\[\n",
    "f(x_1), f(x_2)\n",
    "\\]\n",
    "\n",
    "2. **Distance Metric**: The outputs of the two networks, \\( f(x_1) \\) and \\( f(x_2) \\), are compared using a distance metric \\( D(f(x_1), f(x_2)) \\).\n",
    "\n",
    "\\[\n",
    "D(f(x_1), f(x_2)) = \\|f(x_1) - f(x_2)\\|\n",
    "\\]\n",
    "\n",
    "3. **Contrastive Loss**: The network is trained using a contrastive loss function, which encourages the distance between similar pairs to be small and the distance between dissimilar pairs to be large.\n",
    "\n",
    "\\[\n",
    "\\mathcal{L}(y, D) = (1-y) \\frac{1}{2} D^2 + y \\frac{1}{2} \\max(0, m - D)^2\n",
    "\\]\n",
    "\n",
    "Where \\( y \\) is 0 if the inputs are similar and 1 if they are dissimilar, and \\( m \\) is a margin parameter.\n",
    "\n",
    "### Training\n",
    "\n",
    "Training a Siamese Network involves minimizing the contrastive loss over pairs of inputs, updating the weights of the sub-networks. The network learns to produce embeddings such that similar inputs have embeddings close to each other, and dissimilar inputs have embeddings far apart.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd771422",
   "metadata": {},
   "source": [
    "\n",
    "## Implementation in Python\n",
    "\n",
    "We'll implement a simple Siamese Network using TensorFlow and Keras for a basic image similarity task using the MNIST dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ed1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# Prepare pairs of images and labels for training\n",
    "def create_pairs(x, digit_indices):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
    "    for d in range(10):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = np.random.randint(1, 10)\n",
    "            dn = (d + inc) % 10\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "digit_indices = [np.where(y_train == i)[0] for i in range(10)]\n",
    "tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    "\n",
    "digit_indices = [np.where(y_test == i)[0] for i in range(10)]\n",
    "te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
    "\n",
    "# Define the Siamese Network model\n",
    "def create_base_network(input_shape):\n",
    "    input = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(input)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    return models.Model(input, x)\n",
    "\n",
    "base_network = create_base_network((28, 28, 1))\n",
    "\n",
    "input_a = layers.Input(shape=(28, 28, 1))\n",
    "input_b = layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = layers.Lambda(lambda embeddings: tf.sqrt(tf.reduce_sum(tf.square(embeddings[0] - embeddings[1]), axis=1, keepdims=True)))([processed_a, processed_b])\n",
    "\n",
    "model = models.Model([input_a, input_b], distance)\n",
    "\n",
    "# Compile the model\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return tf.reduce_mean(y_true * tf.square(y_pred) + (1 - y_true) * tf.square(tf.maximum(margin - y_pred, 0)))\n",
    "\n",
    "model.compile(optimizer='adam', loss=contrastive_loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y, batch_size=128, epochs=10, validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate([te_pairs[:, 0], te_pairs[:, 1]], te_y)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38645778",
   "metadata": {},
   "source": [
    "\n",
    "## Pros and Cons of Siamese Networks\n",
    "\n",
    "### Advantages\n",
    "- **Effective for Similarity Tasks**: Siamese Networks are particularly effective for tasks that require learning a similarity metric, such as face verification and signature verification.\n",
    "- **One-Shot Learning**: Siamese Networks excel in one-shot learning tasks, where the model needs to learn from just a few examples.\n",
    "\n",
    "### Disadvantages\n",
    "- **Pairwise Training**: Siamese Networks require training on pairs of inputs, which can be computationally expensive and challenging to scale to large datasets.\n",
    "- **Limited Generalization**: The performance of Siamese Networks can be limited by the quality and diversity of the training pairs, which may impact their generalization to unseen examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b981c65b",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "Siamese Networks offer a powerful approach for learning similarity metrics, making them well-suited for tasks such as verification, one-shot learning, and anomaly detection. Despite their effectiveness, they come with challenges related to computational complexity and generalization, which require careful consideration when deploying these models in real-world applications.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
