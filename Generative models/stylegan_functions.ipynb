{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94536d3",
   "metadata": {},
   "source": [
    "# Most Used Functions in StyleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ba8c1",
   "metadata": {},
   "source": [
    "StyleGAN is a type of Generative Adversarial Network (GAN) known for its ability to generate high-quality images. It introduces the concepts of the mapping network and the synthesis network, along with style mixing and adaptive instance normalization (AdaIN). In this notebook, we will cover some of the most commonly used functions and techniques for implementing a simplified version of StyleGAN using TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad9c63",
   "metadata": {},
   "source": [
    "## 1. Building the Mapping Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a151a928",
   "metadata": {},
   "source": [
    "The mapping network in StyleGAN is responsible for mapping the latent code \\( z \\) to an intermediate latent space \\( w \\). This network consists of several fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf                \n",
    "\n",
    "# Function to build the mapping network\n",
    "def build_mapping_network(latent_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(512, input_dim=latent_dim, activation='relu'))\n",
    "    for _ in range(7):\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the mapping network\n",
    "latent_dim = 100\n",
    "mapping_network = build_mapping_network(latent_dim)\n",
    "mapping_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d277dc4",
   "metadata": {},
   "source": [
    "## 2. Building the Synthesis Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a2433",
   "metadata": {},
   "source": [
    "The synthesis network in StyleGAN generates images from the intermediate latent space \\( w \\). It progressively grows in resolution by adding layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ab871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Reshape, Activation, BatchNormalization, Add\n",
    "\n",
    "# Function to build the synthesis network\n",
    "def build_synthesis_network():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(4*4*512, activation='relu', input_dim=512))\n",
    "    model.add(Reshape((4, 4, 512)))\n",
    "    model.add(Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(3, (3, 3), padding='same', activation='tanh'))\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the synthesis network\n",
    "synthesis_network = build_synthesis_network()\n",
    "synthesis_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b461de9",
   "metadata": {},
   "source": [
    "## 3. Building the Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b175321",
   "metadata": {},
   "source": [
    "The discriminator in StyleGAN is similar to that in other GANs, distinguishing between real and fake images. It progressively reduces the resolution by adding convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# Function to build the discriminator\n",
    "def build_discriminator(input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(512, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the discriminator\n",
    "discriminator = build_discriminator((32, 32, 3))\n",
    "discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e8f15",
   "metadata": {},
   "source": [
    "## 4. Building and Compiling the StyleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fbb6de",
   "metadata": {},
   "source": [
    "The StyleGAN combines the mapping network, synthesis network, and discriminator. The generator network consists of the mapping and synthesis networks. The GAN is trained using the combined model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad829b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the StyleGAN\n",
    "def build_stylegan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = tf.keras.Sequential([generator, discriminator])\n",
    "    model.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "# Create inputs\n",
    "z = Input(shape=(latent_dim,))\n",
    "w = mapping_network(z)\n",
    "img = synthesis_network(w)\n",
    "\n",
    "# Create generator model\n",
    "generator = Model(z, img)\n",
    "generator.summary()\n",
    "\n",
    "# Create and compile GAN model\n",
    "stylegan = build_stylegan(generator, discriminator)\n",
    "stylegan.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
