{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba2409b",
   "metadata": {},
   "source": [
    "\n",
    "# Variational Autoencoder (VAE): A Comprehensive Overview\n",
    "\n",
    "This notebook provides an in-depth overview of the Variational Autoencoder (VAE) architecture, including its history, mathematical foundation, implementation, usage, advantages and disadvantages, and more. We'll also include visualizations and a discussion of the model's impact and applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96021d2e",
   "metadata": {},
   "source": [
    "\n",
    "## History of Variational Autoencoders\n",
    "\n",
    "Variational Autoencoders (VAEs) were introduced by Kingma and Welling in their 2013 paper \"Auto-Encoding Variational Bayes.\" VAEs are a type of generative model that introduces a probabilistic twist to the traditional autoencoder architecture. By learning a distribution over the latent space, VAEs can generate new data points similar to the training data, making them a powerful tool for tasks such as generative modeling, anomaly detection, and unsupervised learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa548a",
   "metadata": {},
   "source": [
    "\n",
    "## Mathematical Foundation of Variational Autoencoder\n",
    "\n",
    "### Architecture\n",
    "\n",
    "A Variational Autoencoder consists of two main components:\n",
    "\n",
    "1. **Encoder**: The encoder maps the input data \\( x \\) to a latent space represented by a mean vector \\( \\mu \\) and a standard deviation vector \\( \\sigma \\), which define a Gaussian distribution.\n",
    "\n",
    "\\[\n",
    "\\mu, \\sigma = f(x) = W x + b\n",
    "\\]\n",
    "\n",
    "The latent variable \\( z \\) is then sampled from this distribution:\n",
    "\n",
    "\\[\n",
    "z = \\mu + \\sigma \\odot \\epsilon\n",
    "\\]\n",
    "\n",
    "where \\( \\epsilon \\) is sampled from a standard normal distribution \\( \\mathcal{N}(0, I) \\).\n",
    "\n",
    "2. **Decoder**: The decoder maps the latent variable \\( z \\) back to the data space to reconstruct the input.\n",
    "\n",
    "\\[\n",
    "\\hat{x} = g(z) = W'z + b'\n",
    "\\]\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "The loss function of a VAE consists of two terms:\n",
    "\n",
    "1. **Reconstruction Loss**: Measures how well the decoder reconstructs the input data from the latent representation.\n",
    "\n",
    "\\[\n",
    "\\text{Reconstruction Loss} = -\\mathbb{E}_{q(z|x)}[\\log p(x|z)]\n",
    "\\]\n",
    "\n",
    "2. **KL Divergence**: Regularizes the latent space by measuring how much the learned distribution \\( q(z|x) \\) diverges from a standard normal distribution \\( p(z) \\).\n",
    "\n",
    "\\[\n",
    "\\text{KL Divergence} = D_{KL}(q(z|x) \\| p(z)) = \\frac{1}{2} \\sum_{i=1}^{n} (1 + \\log(\\sigma_i^2) - \\mu_i^2 - \\sigma_i^2)\n",
    "\\]\n",
    "\n",
    "The overall loss is a combination of these two terms:\n",
    "\n",
    "\\[\n",
    "\\text{Loss} = \\text{Reconstruction Loss} + \\text{KL Divergence}\n",
    "\\]\n",
    "\n",
    "### Training\n",
    "\n",
    "Training a VAE involves backpropagation to minimize the combined loss function, updating the weights of both the encoder and decoder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739e7ed",
   "metadata": {},
   "source": [
    "\n",
    "## Implementation in Python\n",
    "\n",
    "We'll implement a Variational Autoencoder using TensorFlow and Keras on the MNIST dataset, which consists of handwritten digit images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "# Encoder\n",
    "inputs = layers.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation='relu', strides=2, padding='same')(inputs)\n",
    "x = layers.Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# Sampling layer\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation='relu')(decoder_input)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\n",
    "outputs = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "encoder = models.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = models.Model(decoder_input, outputs, name='decoder')\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = models.Model(inputs, outputs, name='vae')\n",
    "\n",
    "# Loss Function\n",
    "reconstruction_loss = tf.keras.losses.binary_crossentropy(inputs, outputs)\n",
    "reconstruction_loss *= 28 * 28\n",
    "kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "kl_loss = tf.reduce_sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "history = vae.fit(x_train, epochs=10, batch_size=128, validation_data=(x_test, None))\n",
    "\n",
    "# Plot the latent space\n",
    "z_mean, _, _ = encoder.predict(x_test)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(z_mean[:, 0], z_mean[:, 1], c='blue')\n",
    "plt.xlabel('z[0]')\n",
    "plt.ylabel('z[1]')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Generate new images from the latent space\n",
    "def plot_images(decoder, n=15, digit_size=28):\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)\n",
    "\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.show()\n",
    "\n",
    "plot_images(decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e8845",
   "metadata": {},
   "source": [
    "\n",
    "## Pros and Cons of Variational Autoencoder\n",
    "\n",
    "### Advantages\n",
    "- **Generative Capabilities**: VAEs can generate new data points similar to the training data, making them useful for tasks like image generation and data augmentation.\n",
    "- **Probabilistic Interpretation**: The latent space in VAEs has a probabilistic interpretation, which allows for meaningful exploration and interpolation in the latent space.\n",
    "\n",
    "### Disadvantages\n",
    "- **Complexity**: VAEs are more complex to implement and train compared to traditional autoencoders.\n",
    "- **Blurriness in Generated Images**: The images generated by VAEs can sometimes be blurry due to the averaging effect of the Gaussian distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d1d240",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "Variational Autoencoders are a powerful extension of traditional autoencoders, providing a probabilistic framework for learning latent representations and generating new data. Despite their complexity, VAEs are widely used in generative modeling and have significantly advanced the field of unsupervised learning. Understanding VAEs is essential for anyone interested in deep learning and generative models.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
